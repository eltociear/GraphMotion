####################################
# The following are general settings
####################################

# Experiment name, more details in Section 'Experiment Name Explanation'
NAME: Experiment
# Debug mode. Set to True will enter the debug mode, then the program will
# 1. use a tiny dataset for trianing and evaluation
# 2. validate more intensively
# 3. will not use `wandb logger`
DEBUG: False
# Devices. Optional: “cpu”, “gpu”
ACCELERATOR: 'gpu'
# Index of GPUs eg. [0] or [0,1,2,3]
DEVICE: [0,1,2,3]

#####################################
# The following are training settings
#####################################
TRAIN:
  # Model stage. Optional: "vae", "diffusion"
  STAGE: diffusion
  # Training dataset name
  DATASETS: ['humanml3d']
  # Number of dataloader workers
  NUM_WORKERS: 8
  # Size of batches
  BATCH_SIZE: 128
  # Total epochs for training
  END_EPOCH: 3000

  RESUME: '' # Resume training from this path
  PRETRAINED_VAE: '' # vae model path
  OPTIM:
    TYPE: AdamW # Optimizer type
    LR: 1e-4 # Learning rate
  # Ablation study configurations.
  ABLATION:
    SKIP_CONNECT: True
    PE_TYPE: GraphMotion
    DIFF_PE_TYPE: GraphMotion

#####################################
# The following are validation settings
#####################################
EVAL:
  DATASETS: ['humanml3d'] # Evaluating datasets
  BATCH_SIZE: 32 # Evaluating Batch size
  SPLIT: test

#####################################
# The following are testing settings
#####################################
TEST:
  CHECKPOINTS: GraphMotion.ckpt # Pretrained model path
  DATASETS: ['humanml3d'] # training datasets
  SPLIT: test
  BATCH_SIZE: 1 # training Batch size
  MEAN: False
  NUM_SAMPLES: 1
  FACT: 1

#####################################
# The following are basic datasets settings
#####################################
DATASET:
  # JOINT_TYPE: 'humanml3d' # join type
  JOINT_TYPE: 'humanml3d' # join type

#####################################
# The following are metric settings
#####################################
METRIC:
  TYPE: ['TemosMetric', 'TM2TMetrics']

#####################################
# The following are training losses settings
#####################################
LOSS:
  TYPE: GraphMotion # Losses type
  LAMBDA_LATENT: 1.0e-5 # Lambda for latent Losses
  LAMBDA_KL: 1.0e-4 # Lambda for kl Losses
  LAMBDA_REC: 1.0 # Lambda for reconstruction Losses
  LAMBDA_GEN: 1.0 # Lambda for text-motion generation losses
  LAMBDA_CROSS: 1.0 # Lambda for reconstruction Losses
  LAMBDA_CYCLE: 0.0 # Lambda for cycle Losses
  LAMBDA_PRIOR: 0.0
  DIST_SYNC_ON_STEP: False # Sync Losses on step when distributed trained

#####################################
# The following are basic model settings
#####################################
model:
  vae: true # whether vae model
  model_type: GraphMotion # model type
  vae_type: GraphMotion
  condition: 'text'
  latent_dim: [1, 256] # latent dimension
  ff_size: 1024 #
  num_layers: 9 # number of layers
  num_head: 4 # number of head layers
  droupout: 0.1 # dropout rate
  activation: gelu # activation type
  guidance_scale: 7.5 #
  guidance_uncondp: 0.1 # 0.1 0.25

  sum_scale: [0.5, 0.3, 0.2]
  num_inference_timesteps_v2: [50, 50, 50]
  denoiser:
    target: GraphMotion.models.architectures.denoiser.Denoiser
    params:
      text_encoded_dim: 768
      ff_size: 4096
      num_layers: 17
      num_heads: 16
      dropout: 0.1
      normalize_before: False
      activation: 'gelu'
      flip_sin_to_cos: True
      return_intermediate_dec: False
      position_embedding: 'learned'
      arch: trans_enc
      freq_shift: 0
      condition: ${model.condition}
      latent_dim: [1, 1024]
      guidance_scale: ${model.guidance_scale}
      guidance_uncondp: ${model.guidance_uncondp}
      nfeats: ${DATASET.NFEATS}
      nclasses: ${DATASET.NCLASSES}
      ablation: ${TRAIN.ABLATION}

motion_vae_stage1:
  # Optional: vae, vposert_vae
  CHECKPOINTS: xxx # Pretrained model path
  target: GraphMotion.models.architectures.vae.Vae
  params:
    arch: 'encoder_decoder'
    ff_size: 1024
    num_layers: 9
    num_heads: 4
    dropout: 0.1
    normalize_before: false
    activation: 'gelu'
    position_embedding: 'learned'
    latent_dim: [2, 256]
    nfeats: ${DATASET.NFEATS}
    ablation: ${TRAIN.ABLATION}

motion_vae_stage2:
  # Optional: vae, vposert_vae
  CHECKPOINTS: xxx # Pretrained model path
  target: GraphMotion.models.architectures.vae.Vae
  params:
    arch: 'encoder_decoder'
    ff_size: 1024
    num_layers: 9
    num_heads: 4
    dropout: 0.1
    normalize_before: false
    activation: 'gelu'
    position_embedding: 'learned'
    latent_dim: [4, 256]
    nfeats: ${DATASET.NFEATS}
    ablation: ${TRAIN.ABLATION}


motion_vae_stage3:
  # Optional: vae, vposert_vae
  CHECKPOINTS: xxx # Pretrained model path
  target: GraphMotion.models.architectures.vae.Vae
  params:
    arch: 'encoder_decoder'
    ff_size: 1024
    num_layers: 9
    num_heads: 4
    dropout: 0.1
    normalize_before: false
    activation: 'gelu'
    position_embedding: 'learned'
    latent_dim: [8, 256]
    nfeats: ${DATASET.NFEATS}
    ablation: ${TRAIN.ABLATION}

#####################################
# The following are loggers settings
#####################################
LOGGER:
  SACE_CHECKPOINT_EPOCH: 10
  LOG_EVERY_STEPS: 1
  VAL_EVERY_STEPS: 10  # 200
  TENSORBOARD: True
  WANDB:
    PROJECT: null
    OFFLINE: False
    RESUME_ID: null
